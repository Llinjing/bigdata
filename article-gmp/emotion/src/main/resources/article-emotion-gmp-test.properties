config.type = us-east-test-config

## kafka
src.kafka.zk.list = 10.10.20.14:2181,10.10.20.15:2181,10.10.20.16:2181
src.kafka.broker.list = 10.10.20.14:9092,10.10.20.15:9092,10.10.20.16:9092
src.kafka.consumer.group = test
src.kafka.batch.size = 2000
src.kafka.sync = false

## topic
topic.click = click-reformat
topic.emotion = ballot-comments
topic.article.emotion.gmp = test
topic.click.partition = 9
topic.emotion.partition = 9
topic.article.emotion.gmp.partition = 6

## spark streaming
sparkstreaming.batch.size.minutes = 5
sparkstreaming.window.num = 1
sparkstreaming.checkpoint = s3://bigdata-east/user/haifeng.huang/spark/checkpoint
sparkstreaming.zk.offset.path = /test/huanghaifeng/offset
sparkstreaming.zk.finish.mark.path = /test/huanghaifeng/finish/mark

## hdfs
hdfs.article.emotion.gmp = s3://bigdata-east/user/haifeng.huang/spark/data/article-emotion-gmp
hdfs.total.decay.feedback = s3://bigdata-east/user/haifeng.huang/spark/data/total-decay-feedback
hdfs.redis = s3://bigdata-east/user/haifeng.huang/spark/data/redis

## threshold
decay_ratio = 0.995
bored_click_threshold = 30
like_click_threshold = 30
angry_click_threshold = 30
sad_click_threshold = 30
total_click_threshold = 8000000

valid_hour = 48
date_format = yyyyMMddHH

## product

## key tag
key_tag = ###

## redis
redis.servers = 10.10.100.100:6300,10.10.100.103:6301,10.10.100.101:6300,10.10.100.104:6301,10.10.100.102:6300,10.10.100.105:6301
redis.port = 6300
redis.cluster = true
redis.password =
redis.hash.key = test-article-emotion-gmp-spark-streaming-hash-key

## debug
debug = true
hdfs_debug = s3://bigdata-east/user/haifeng.huang/spark/data/debug