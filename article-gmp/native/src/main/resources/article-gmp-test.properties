config.type = native-test-config

## kafka
src.kafka.zk.list = 192.168.1.60:2181,192.168.1.61:2181,192.168.1.62:2181
src.kafka.broker.list = 192.168.1.60:9092,192.168.1.61:9092,192.168.1.62:9092
src.kafka.consumer.group = test
src.kafka.batch.size = 2000
src.kafka.sync = false

## topic
topic.click = click-reformat
topic.request = request-reformat
topic.impression = impression-reformat
topic.article.gmp = test_topic_mzy
topic.click.partition = 18
topic.request.partition = 18
topic.impression.partition = 18
topic.article.gmp.partition = 18

## spark streaming
sparkstreaming.batch.size.minutes = 3
sparkstreaming.window.num = 1
sparkstreaming.checkpoint = /test/huanghaifeng/spark/checkpoint
sparkstreaming.zk.offset.path = /test/huanghaifeng/offset
sparkstreaming.zk.finish.mark.path = /test/huanghaifeng/finish/mark

## hdfs
hdfs.request = /test/huanghaifeng/spark/data/request
hdfs.impression = /test/huanghaifeng/spark/data/impression
hdfs.article.gmp = /test/huanghaifeng/spark/data/article-gmp
hdfs.total.decay.feedback = /test/huanghaifeng/spark/data/total-decay-feedback
hdfs.redis = /test/huanghaifeng/spark/data/redis

## decay
decay_ratio = 0.995
impression_threshold = 50
impression_threshold_meizu = 30

valid_hour = 48
date_format = yyyyMMdd

## product
product_id_meizu = meizu
product_id_ali = ali
product_id_tcl = tcl
product_id_duowei = duowei
product_id_xiaolajiao = xiaolajiao
product_id_union_tcl_dw_xlj = union_tcl_dw_xlj

## key tag
key_tag = ###
product_key_tag = ___

## redis
redis.servers = 192.168.1.12:6379,192.168.1.27:6379,192.168.1.238:6379,192.168.1.81:9379,192.168.1.82:9379,192.168.1.83:9379,192.168.1.84:9379,192.168.1.85:9379
redis.port = 9379
redis.cluster = true
redis.password =
redis.hash.key = test-gmp-spark-streaming-test
redis.hash.key.prefix = test-article-gmp-spark-streaming-hash-key
redis.hash.key.partitions = 100

## debug
debug = true
hdfs_debug = /test/huanghaifeng/spark/data/debug
